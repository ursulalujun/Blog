---
layout: post
title: 理解标准卷积及其各种变式
date: 2023-01-19
Author: Ursula
tags: [ML]
comments: true
toc: true
--- 

（更新中）

这是一篇梳理和总结性质的博客，写得很不详细，但我觉得重要的地方都给出了相关链接，供大家参考 ❀ ❀

# 卷积相关的术语
新手可能会不太熟悉的一些词语，请ChatGPT来为大家解释一下
![image](https://user-images.githubusercontent.com/73097943/227718104-8720bf53-dd9d-4f2b-bb4b-e028b48d2faa.png)

# 各种卷积
## standard convolution
怎么操作的？参见这篇[blog](https://yinguobing.com/separable-convolution/#fn2)，注意把握维度变化

![image](https://github.com/ursulalujun/blog/assets/73097943/ff97ce6b-73d9-49b4-ab9e-b2cf042cb788)

![image](https://github.com/ursulalujun/blog/assets/73097943/65982aa4-0bf7-4e5b-bfe2-de44206a9a74)


从两种角度理解，参见[李宏毅讲解CNN](https://www.bilibili.com/video/BV1Lb411b7BS/?vd_source=9da8a8ddd09633f1154195a4e101a0d4)：
- filter提取局部特征
- 把filter中的每个pixel上的参数看作是神经网络的连接参数，就形成了在input patch之间**共享权重的子神经网络**（每个输出神经元和部分输入神经元连接）

## group convolution

![image](https://github.com/ursulalujun/blog/assets/73097943/6bd63b11-5f28-419b-b7ec-d260f529613f)

## depthwise seperable covolution
depthwise seperable covolution = depth-wise Conv + point-wise Conv，深度分离的主要作用是减少参数，详情还是看这篇[blog](https://yinguobing.com/separable-convolution/#fn2)

1×1卷积的性质和作用：
- 结合上文提到的理解卷积的第二种角度，相当于全连接，所以不会改变空间维度，只改变通道维度
- 改变通道维度（通常是降维以减少计算量）的同时完成了通道之间的信息交互和整合
- 在保持宽和高不变的前提下，能够增加网络深度，通过在卷积后通过非线性激活函数可以有效增强网络的表达能力。

还有一种可分离卷积是空间可分离，主要原理是将一个kxk的卷积核拆成kx1和1xk两个方向的卷积核分别对输入特征图进行卷积，以降低复杂度。

## adaptive convolution
标准卷积有两个性质
- shift-invariant或者spatial-agnostic：空间位置不同的patch共享kernel
- channel-specific：每个通道的filter是不同的

### pixel-adaptive
根据patch生成自适应的weight，weight与卷积核相乘，仍然保留了卷积channel-specific的特性，但没有完成通道维度的自适应。

### Involution
有着与卷积相反的特性
下图中的卷积核$H_{i,j}$是对$X_{i,j}$进行两次 `1*1`卷积，然后reshape、duplication生成的，用这个生成的卷积核来对patch做depth-wise Conv，即文中所说的multiply-add操作，所以就是自己卷自己，called 内卷。
![image](https://user-images.githubusercontent.com/73097943/227722656-e63346c3-9ee4-478a-8af7-ab8a6f61624c.png)

Tricks：当你想要同时使用两种性质互补的卷积方式时可以采用dual complementary CNN结构，或者考虑加一个补充信息的bias

# kernel size
有很多文章探究kernel size的设置

eg1：到底是大卷积好还是叠多个小卷积增加深度好？[这篇论文](https://arxiv.org/abs/2203.06717)提出了使用31*31的大卷积，并结合有效感受野（ERF）对这种方案的有效性做出了分析

eg2：GoogLeNet中使用的inception block 通过多个kernel size不同的卷积运算来捕获更多尺度的上下文信息，最后再通过拼接操作聚合输出，已获得多尺度特征表示。

参考文献
[1] [知乎文章 卷积变体](https://zhuanlan.zhihu.com/p/393200454)

