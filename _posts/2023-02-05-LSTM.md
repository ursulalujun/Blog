---
layout: post
title: 理解LSTM（结合keras/pytorch代码）
date: 2023-02-05
Author: Ursula
tags: [DL]
comments: true
--- 

hidden_size
tensorflow代码
```python
init_lstm_cell, init_lstm_hidden = self.lstm_cell_ph, self.lstm_hidden_ph
lstm_cell_state = tf.reshape(init_lstm_cell, [-1, self.lstm_unit_size])
lstm_hidden_state = tf.reshape(init_lstm_hidden, [-1, self.lstm_unit_size])
lstm_initial_state = tf.nn.rnn_cell.LSTMStateTuple(
    lstm_cell_state, lstm_hidden_state
)

lstm_cell = tf.contrib.rnn.BasicLSTMCell(
    num_units=self.lstm_unit_size, forget_bias=1.0
)
with tf.variable_scope("rnn"):
    state = lstm_initial_state
    lstm_output_list = []
    for step in range(self.lstm_time_steps):
        lstm_output, state = lstm_cell(
            reshape_fc_public_result[:, step, :], state
        )
        lstm_output_list.append(lstm_output)
    lstm_outputs = tf.concat(lstm_output_list, axis=1, name="lstm_outputs")
    self.lstm_cell_output = state.c
    self.lstm_hidden_output = state.h
reshape_lstm_outputs_result = tf.reshape(
    lstm_outputs,
    [-1, self.lstm_unit_size],
    name="reshape_lstm_outputs_result",
)
```
http://colah.github.io/posts/2015-08-Understanding-LSTMs/
[图的出处](https://blog.csdn.net/baidu_38963740/article/details/117197619#:~:text=Pytorch%E4%B8%ADLSTM%20%E5%90%84%20%E5%8F%82%E6%95%B0%20%E8%A7%A3%E9%87%8A%20import%20torch%20import%20torch.nn,%E5%A6%82%E6%9E%9C%E6%98%AF1%2C%E5%8F%AF%E4%BB%A5%E7%9C%81%E7%95%A5%2C%E9%BB%98%E8%AE%A4%E4%B8%BA1%29%20input%20%3D...%20LSTM%20%E5%8E%9F%E7%90%86%E3%80%81%20%E5%8F%82%E6%95%B0%20%E4%BB%8B%E7%BB%8D%E3%80%81Keras%20%E5%AE%9E%E7%8E%B0)
[另一篇帮助理解LSTM参数的文章](https://zhuanlan.zhihu.com/p/36455374)
