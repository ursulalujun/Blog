---
layout: post
title: GPT会不会算法（GPT3.5实测）
date: 2023-03-22
Author: Ursula
tags: [ML]
comments: true
--- 

我用最近做过的一些算法题对ChatGPT（GPT3.5）进行了测试，如果有厉害的（富有的）小伙伴有机会使用GPT4.0的话，可以做同样的测试对比一下效果。

模拟运行是指给出样例，让GPT模拟运行代码，给出输出

板子题

|题目来源|算法标签|编译&运行|思路|模拟运行|AC？|出错原因|
| ---- | ---- | ---- | ---- | ---- |---- |---- |
|石子合并|区间DP|运行出错|正确，使用区间DP模板|出错|RE|计算合并两堆石子的得分时出错，循环边界出错，没考虑环|
|国王问题|状压DP|无报错|错误，使用DFS，和每行每列只能放一个的问题弄混了|出错|WA|虽然把问题弄混了，但DFS的代码主体每一点问题，图中记录的更新，返回条件啥的都对了|

模拟

|题目来源|算法标签|编译&运行|思路|模拟运行|AC？|出错原因|
| ---- | ---- | ---- | ---- | ---- |---- |---- |
|CSP2022-12-No.1|小模拟（测试时未给出计算利率的公式）|无报错|正确，给出了利率公式|错误，见图一|AC|无|
|洛谷 表达式转换|栈+模拟（涉及一些算法设计）|network error未生成完整代码|基本正确，使用双栈|无|无|试了三次都network error|

一些算法不复杂但比较灵活的题

|题目来源|算法标签|编译&运行|思路|模拟运行|AC？|出错原因|
| ---- | ---- | ---- | ---- | ---- |---- |---- |
|蓝桥杯（左孩子右兄弟）|贪心+递归      |无报错      |递归正确，试图贪心|错误|WA|贪心没贪对（这个需要一点分析，我也是画了几棵树才找出规律）|



图一：解题思路都是对的，但是居然在最后一步的加减法上出了计算错误，它是在用学语言的方法学数学？

![image](https://user-images.githubusercontent.com/73097943/226919442-db2388aa-6fe5-4b14-89f7-5a0e054a5073.png)

接下来我想试探一下它到底是怎么算的

![image](https://user-images.githubusercontent.com/73097943/227087613-2c270094-62d5-4a4a-85a0-a2ce3057be61.png)
![image](https://user-images.githubusercontent.com/73097943/227087764-9e7bc81c-7ead-4c0a-b68e-a1304b9f0c51.png)
![image](https://user-images.githubusercontent.com/73097943/227087876-032cd321-2152-45a3-8198-1e1f83548e00.png)
![image](https://user-images.githubusercontent.com/73097943/227088003-80f9db61-9a8c-42a8-b234-d1c22cee52a4.png)
![image](https://user-images.githubusercontent.com/73097943/227088078-7acad152-ee6f-4331-bf54-d71f9b6c30b4.png)
![image](https://user-images.githubusercontent.com/73097943/227088118-2a4ed135-b2e4-4678-9e2c-707addd8122b.png)

可以看到我花了很大力气纠正它的智障的数学错误，但也有些地方显得非常聪明，比如我只提示让它做第一步计算，它马上知道自己算错了，把整个重算了一遍，它的上下文理解和记忆是真的强，最后我问它最初的问题是什么它也还记得，大模型不可解释，它本身不知道自己的结果是如何生成的，但是我在想会不会把问题输入模型之前做了一些任务拆分，引导它一步步算，所以试探了一下它是否知道自己的计算过程，但它好像确实没有拆分处理，然后它所说的漏掉了步骤什么的都是根据语境编出来。ChatGPT的算术能力是真的很差，之前看李宏毅老师测试GPT4鸡兔同笼问题，它能列对式子，但却解不对方程，不过ToolFormer之类的概念出来之后，GPT可以调用计算器来算，准确率应该会提升很多。

总结：

以上测试中，代码的输入输出格式没有出现过问题，没出现过编译错误，运行时可能出错。

能正确完成小模拟，一般能正确判断要使用那种算法，并能给出正确的板子，但填写板子的时候会出一些小问题，有的时候反而是在人类看来很简单的地方出错。

给样例让它模拟运行的错误率特别高，输出基本都是错的。（如果你在题目中告诉它样例的正确输出，再让它模拟运行的话，它就会给出正确输出哈哈）

出错点经常是简单的地方，比如公式对了算错的、DP的模板对了不知道怎么求区间和等等，AI和人类眼中的难易程度未必相同

代码格式非常规范，分段写注释，重点语句后面也会加注释，比某粗枝大叶三个月后就看不懂自己代码的程序员好太多（bushi。

最后是我的一点想法：

能完成小模拟是意料之中，不知道是不是我找的题目太常见了，它的训练集中都有，所以基本能用对板子。模拟运行错误很多可能是因为它并没有真正的模拟运行，只是在根据语境编造结果，它毕竟是一个语言模型，本质上是在预测下一段话，代码也是一种语言，而且它从人类语言中学到了解决方案（算法），所以它能写得很好，但数学计算、解方程、代入数字求解等似乎就不太行，据宣传，GPT4.0做SAT数学考试都能得700分（满分800），而且GPT3.5就已经能考590分了，我对这个结果存有很大疑惑，因为无论是我的实测体验还是看别人的实测视频，GPT3.5做数学题的能力都非常差，小学数学都未必及格，不过这也符合它作为语言模型的特点，不知道这种问题能不能通过在训练集中加入大量规范的求解方案（首先规定个位数的计算结果，然后规定哪一步加哪一位，什么时候应该进退位之类的）来实现，至于SAT MATH的结果我大胆推测一下，会不会是因为SAT的题目大多使用符号或变量而不是常数，数字计算较少（积分求导之类的都可以背公式），然后做测试的模型可能是被喂了大量很干净的数学题题库喂出来的，和发布版被污染过的模型不是同一个？不过真的已经很厉害了，即使是加减运算也依赖很复杂的解决方案，在没有专门的软硬件支持的情况下，仅靠从语言出发的逻辑推理来完成简直amazing。

![image](https://user-images.githubusercontent.com/73097943/227078419-5b6d72e7-bf91-4ffc-bbd6-75e2b2b0cafe.png)


即便GPT4.0的实测效果没那么好，还是会在某些关键点上出错，但提供从算法到代码的翻译、算法板子等功能也已经足够强大了，能极大程度上提高编程率，让程序员只关注最核心的代码。

ChatGPT出来之前我觉得现在的DL都是在堆积木、炼丹，沿着当前的路子也未必能走出AGI，现在看来鼠鼠真是学的太浅，大佬炼的丹和我的怎么可能是同一个东西啊，而且训练和align大模型本身就是很NB的工程技术，事实证明，量变能引起质变，大力能出得了奇迹，可能新的时代真的到来了吧。
